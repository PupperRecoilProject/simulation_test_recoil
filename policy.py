# policy.py
import numpy as np
import onnxruntime as ort
import sys
import os
import time
from collections import deque
from typing import TYPE_CHECKING, List, Dict

if TYPE_CHECKING:
    from config import AppConfig
    from observation import ObservationBuilder
    from rendering import DebugOverlay # <-- æ–°å¢

class PolicyManager:
    def __init__(self, config: 'AppConfig', obs_builder: 'ObservationBuilder', overlay: 'DebugOverlay'): # <-- æ¥æ”¶ overlay
        self.config = config
        self.obs_builder = obs_builder
        self.overlay = overlay # <-- å„²å­˜ overlay çš„åƒè€ƒ
        self.sessions: Dict[str, ort.InferenceSession] = {}
        self.model_recipes: Dict[str, List[str]] = {}
        self.model_history_lengths: Dict[str, int] = {}
        self.model_names: List[str] = []
        
        print("--- æ­£åœ¨è¼‰å…¥æ‰€æœ‰ ONNX æ¨¡å‹åŠå…¶é…æ–¹ ---")
        for name, model_info in config.onnx_models.items():
            path = model_info.get('path')
            recipe = model_info.get('observation_recipe')

            if not path or not recipe:
                print(f"    âš ï¸ è­¦å‘Š: æ¨¡å‹ '{name}' ç¼ºå°‘ 'path' æˆ– 'observation_recipe'ï¼Œå·²è·³éã€‚")
                continue

            print(f"  - è¼‰å…¥æ¨¡å‹ '{name}' å¾: {path}")
            try:
                sess_options = ort.SessionOptions()
                cache_path = os.path.splitext(path)[0] + ".optimized.ort"
                sess_options.optimized_model_filepath = cache_path
                sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
                session = ort.InferenceSession(path, sess_options=sess_options, providers=['CPUExecutionProvider'])

                self.obs_builder.set_recipe(recipe)
                base_obs_dim = len(self.obs_builder.get_observation(np.zeros(3), np.zeros(config.num_motors)))
                model_input_dim = session.get_inputs()[0].shape[1]
                history_len = 1
                if base_obs_dim > 0 and model_input_dim % base_obs_dim == 0:
                    history_len = model_input_dim // base_obs_dim
                
                self.sessions[name] = session
                self.model_recipes[name] = recipe
                self.model_history_lengths[name] = history_len
                self.model_names.append(name)
                print(f"    > é…æ–¹: {recipe}")
                print(f"    > åŸºç¤ç¶­åº¦: {base_obs_dim}, æ¨¡å‹è¼¸å…¥: {model_input_dim}, æ¨æ–·æ­·å²é•·åº¦: {history_len}")

            except Exception as e:
                print(f"    âŒ éŒ¯èª¤: ç„¡æ³•è¼‰å…¥æ¨¡å‹ '{name}'ã€‚éŒ¯èª¤: {e}")

        if not self.sessions:
            sys.exit("âŒ è‡´å‘½éŒ¯èª¤: æœªèƒ½æˆåŠŸè¼‰å…¥ä»»ä½• ONNX æ¨¡å‹ã€‚")

        self.active_policy_name = self.model_names[0]
        self.last_action = np.zeros(config.num_motors, dtype=np.float32)
        self.obs_history = None
        self.is_transitioning = False
        self.transition_start_time = 0.0
        self.old_policy_output = np.zeros(config.num_motors, dtype=np.float32)

        self.reset()

        print("--- æ­£åœ¨é ç†±æ‰€æœ‰ ONNX æ¨¡å‹ (å¼·åˆ¶é€²è¡Œé¦–æ¬¡æ¨è«–å„ªåŒ–)... ---")
        for name, session in self.sessions.items():
            input_name = session.get_inputs()[0].name
            output_name = session.get_outputs()[0].name
            model_input_dim = session.get_inputs()[0].shape[1]
            dummy_input = np.zeros((1, model_input_dim), dtype=np.float32)
            try:
                session.run([output_name], {input_name: dummy_input})
                print(f"  - æ¨¡å‹ '{name}' é ç†±æˆåŠŸã€‚")
            except Exception as e:
                print(f"  - âš ï¸ æ¨¡å‹ '{name}' é ç†±å¤±æ•—: {e}")

        print(f"âœ… ç­–ç•¥ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç•¶å‰å•Ÿç”¨æ¨¡å‹: '{self.active_policy_name}'")

    def switch_policy(self, new_policy_name: str):
        if new_policy_name not in self.sessions:
            print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•åˆ‡æ›ï¼Œæ¨¡å‹ '{new_policy_name}' ä¸å­˜åœ¨ã€‚")
            return
        if new_policy_name == self.active_policy_name and not self.is_transitioning:
            return

        print(f"ğŸš€ é–‹å§‹å¾ '{self.active_policy_name}' å¹³æ»‘éæ¸¡åˆ° '{new_policy_name}'...")
        self.is_transitioning = True
        self.transition_start_time = time.time()
        self.old_policy_output = self.last_action.copy()
        self.active_policy_name = new_policy_name
        self.reset()

    def get_action(self, command: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        base_obs = self.obs_builder.get_observation(command, self.last_action)
        self.obs_history.append(base_obs)
        onnx_input = np.concatenate(list(self.obs_history)).astype(np.float32).reshape(1, -1)
        session = self.sessions[self.active_policy_name]
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name

        if onnx_input.shape[1] != session.get_inputs()[0].shape[1]:
            action_raw = np.zeros(self.config.num_motors, dtype=np.float32)
        else:
            action_raw = session.run([output_name], {input_name: onnx_input})[0].flatten()

        if self.is_transitioning:
            elapsed = time.time() - self.transition_start_time
            duration = self.config.policy_transition_duration
            if duration <= 0 or elapsed >= duration:
                self.is_transitioning = False
                final_action = action_raw
                if duration > 0: print(f"âœ… å·²å®Œæˆåˆ° '{self.active_policy_name}' çš„éæ¸¡ã€‚")
            else:
                alpha = elapsed / duration
                smooth_alpha = alpha * alpha * (3.0 - 2.0 * alpha)
                final_action = (1.0 - smooth_alpha) * self.old_policy_output + smooth_alpha * action_raw
        else:
            final_action = action_raw

        self.last_action[:] = final_action
        return onnx_input, final_action

    def reset(self):
        """é‡ç½®è§€å¯Ÿæ­·å²ä¸¦åŒæ­¥åˆ‡æ›è§€å¯Ÿé…æ–¹ã€‚"""
        active_recipe = self.model_recipes[self.active_policy_name]
        
        # ã€ä¿®æ”¹ã€‘åŒæ™‚æ›´æ–° obs_builder å’Œ overlay çš„é…æ–¹
        self.obs_builder.set_recipe(active_recipe)
        if self.overlay:
            self.overlay.set_recipe(active_recipe)

        history_length = self.model_history_lengths[self.active_policy_name]
        base_obs_dim = len(self.obs_builder.get_observation(np.zeros(3), np.zeros(self.config.num_motors)))

        self.obs_history = deque(
            [np.zeros(base_obs_dim, dtype=np.float32)] * history_length, 
            maxlen=history_length
        )
        print(f"âœ… ç­–ç•¥ç‹€æ…‹å·²ç‚º '{self.active_policy_name}' é‡ç½® (History: {history_length}, Obs Dim: {base_obs_dim})ã€‚")